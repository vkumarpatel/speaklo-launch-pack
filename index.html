<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <title>Speaklo Tala Demo</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/bodymovin/5.9.6/lottie.min.js"></script>
  <style>
    body{font-family:Inter,Arial;display:flex;align-items:center;justify-content:center;height:100vh;background:#f5fbff;margin:0}
    .card{width:360px;padding:18px;border-radius:18px;background:white;box-shadow:0 8px 30px rgba(10,31,68,0.08);text-align:center}
    #anim{width:220px;height:220px;margin:0 auto;position:relative}
    .mouth { position:absolute; left:50%; transform:translateX(-50%); bottom:80px; width:64px; height:16px; background:#0a1f44; border-radius:10px; transition:height .06s ease, transform .06s ease; }
    .controls{margin-top:14px;display:flex;gap:10px;justify-content:center}
    button{padding:10px 14px;border-radius:10px;border:none;background:#0a1f44;color:#fff;font-weight:700;cursor:pointer}
    .small{background:transparent;color:#0a1f44;border:2px solid #0a1f44}
  </style>
</head>
<body>
  <div class="card">
    <div id="anim"></div>
    <div class="mouth" id="mouth"></div>
    <div class="controls">
      <button id="welcome">Play Welcome</button>
      <button id="startMic" class="small">Start Mic</button>
      <button id="stopMic" class="small">Stop Mic</button>
    </div>
    <p style="color:#0a1f44;font-weight:600;margin-top:12px">Speaklo — Tala (Energetic)</p>
  </div>

<script>
  // Lottie JSON file must be in the same folder and named speaklo_tala.json
  const LOTTIE_JSON = 'speaklo_tala.json';
  const animContainer = document.getElementById('anim');
  const anim = lottie.loadAnimation({
    container: animContainer,
    renderer: 'svg',
    loop: true,
    autoplay: true,
    path: LOTTIE_JSON
  });

  // TTS welcome
  document.getElementById('welcome').onclick = () => {
    const text = "Hi — I'm Tala, your Speaklo coach. Ready for three minutes of practice?";
    const u = new SpeechSynthesisUtterance(text);
    u.rate = 0.95; u.pitch = 1;
    const voices = speechSynthesis.getVoices();
    const en = voices.find(v => v.lang.startsWith('en')) || voices[0];
    if(en) u.voice = en;
    speechSynthesis.cancel();
    speechSynthesis.speak(u);
  };

  // Mic -> mouth animation
  let audioCtx, analyser, micStream, rafId;
  const mouth = document.getElementById('mouth');

  async function startMic() {
    if (micStream) return;
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    micStream = stream;
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioCtx.createMediaStreamSource(stream);
    analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);
    const data = new Uint8Array(analyser.frequencyBinCount);

    function tick() {
      analyser.getByteFrequencyData(data);
      let sum = 0; for(let i=0;i<data.length;i++) sum += data[i]*data[i];
      const rms = Math.sqrt(sum / data.length);
      const h = Math.max(10, Math.min(56, 14 + (rms/3)));
      mouth.style.height = h + 'px';
      mouth.style.transform = `translateX(-50%) scaleX(${1 + Math.min(0.6, rms/220)})`;
      rafId = requestAnimationFrame(tick);
    }
    tick();
  }

  async function stopMic() {
    if(rafId) cancelAnimationFrame(rafId);
    if(analyser) analyser.disconnect();
    if(audioCtx) audioCtx.close();
    if(micStream){ micStream.getTracks().forEach(t => t.stop()); micStream = null; }
    mouth.style.height = '16px'; mouth.style.transform = 'translateX(-50%) scaleX(1)';

    // after stopping mic, trigger in-browser STT & reply (Web Speech API)
    // This uses SpeechRecognition (Chrome). If unsupported, fallback to echo reply.
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition || null;
    if (SpeechRecognition) {
      try {
        const recognition = new SpeechRecognition();
        recognition.lang = 'en-US';
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;
        recognition.onresult = (event) => {
          const transcript = event.results[0][0].transcript;
          console.log('Transcript:', transcript);
          // build a simple reply (replace with server LLM call for real corrections)
          const reply = `I heard: "${transcript}". Nice! Try repeating with a little more pace.`;
          robotSpeak(reply, 0.9, 'en-US');
          showCorrectionUI(transcript, reply);
        };
        recognition.onerror = (e) => {
          console.warn('Recognition error', e);
          robotSpeak("Sorry, I couldn't hear that clearly. Try again please.");
        };
        recognition.onend = () => { console.log('Recognition ended'); };
        recognition.start();
      } catch (err) {
        console.warn('SpeechRecognition error', err);
        robotSpeak("Speech recognition not supported here.");
      }
    } else {
      robotSpeak("I can't transcribe here, but you're doing great. Keep practicing!");
    }
  }

  document.getElementById('startMic').onclick = startMic;
  document.getElementById('stopMic').onclick = stopMic;

  // robotSpeak + mouth animation during TTS
  function animateMouthDuring(ttsUtterance) {
    const mouthEl = document.getElementById('mouth');
    let animInterval;
    ttsUtterance.onstart = () => {
      let grow = 0;
      animInterval = setInterval(()=>{
        const h = 16 + 8 * (0.5 + Math.sin(Date.now()/80 + (grow++ % 10)));
        mouthEl.style.height = Math.max(10, Math.min(56, h)) + 'px';
        mouthEl.style.transform = `translateX(-50%) scaleX(${1 + ((grow % 6)/10)})`;
      }, 60);
    };
    ttsUtterance.onend = () => {
      clearInterval(animInterval);
      mouthEl.style.height = '16px';
      mouthEl.style.transform = 'translateX(-50%) scaleX(1)';
    };
  }

  function robotSpeak(text, rate=0.9, lang='en-US') {
    const u = new SpeechSynthesisUtterance(text);
    u.rate = rate;
    u.lang = lang;
    const vlist = speechSynthesis.getVoices();
    const v = vlist.find(v=>v.lang.startsWith('en')) || vlist[0];
    if(v) u.voice = v;
    animateMouthDuring(u);
    speechSynthesis.cancel();
    speechSynthesis.speak(u);
  }

  // UI show correction
  function showCorrectionUI(orig, reply) {
    let container = document.getElementById('correction');
    if(!container) {
      container = document.createElement('div');
      container.id = 'correction';
      container.style.marginTop = '12px';
      container.style.fontSize = '14px';
      container.style.color = '#0a1f44';
      document.querySelector('.card').appendChild(container);
    }
    container.innerHTML = `<div style="text-align:left"><strong>You said:</strong><div style="background:#f1f5f9;padding:8px;border-radius:8px;margin-top:6px">${escapeHtml(orig)}</div>
  <strong style="margin-top:8px;display:block">Speaklo says:</strong>
  <div style="background:#e6fffa;padding:8px;border-radius:8px;margin-top:6px">${escapeHtml(reply)}</div></div>`;
  }
  function escapeHtml(s){ return (s||'').replace(/&/g,'&amp;').replace(/</g,'&lt;'); }

</script>
</body>
</html>
